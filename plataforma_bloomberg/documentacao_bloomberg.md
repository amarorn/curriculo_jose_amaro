
# üìò Plataforma Bloomberg ‚Äî Documenta√ß√£o T√©cnica Completa

> **Documento oficial do Data Product Bloomberg**
> Arquitetura ‚Ä¢ Fluxos ‚Ä¢ C√°lculos ‚Ä¢ Regras de Neg√≥cio ‚Ä¢ Governan√ßa ‚Ä¢ Opera√ß√£o

---

## 1. Vis√£o Geral do Produto

A **Plataforma Bloomberg** √© um **Data Product financeiro corporativo**, projetado para a ingest√£o, padroniza√ß√£o, c√°lculo e disponibiliza√ß√£o de s√©ries financeiras di√°rias com um alto grau de confiabilidade, auditabilidade e rastreabilidade. O principal objetivo da plataforma √© fornecer uma fonte centralizada e confi√°vel de dados financeiros para suportar decis√µes de neg√≥cio cr√≠ticas em toda a organiza√ß√£o.

O produto final entregue aos consumidores de dados √© o **data mart `dm_bloomberg`**. Este data mart consolida uma vasta gama de informa√ß√µes, incluindo pre√ßos de ativos, s√©ries temporais cont√≠nuas e uma variedade de indicadores financeiros derivados. Os dados s√£o pr√©-processados e estruturados para estarem prontos para consumo imediato por ferramentas de Business Intelligence (BI), APIs de sistemas internos e modelos de an√°lises avan√ßadas.

### Objetivos do Produto

Os objetivos estrat√©gicos que norteiam o desenvolvimento e a opera√ß√£o da Plataforma Bloomberg s√£o:

- **Centralizar Fontes de Dados:** Unificar dados financeiros provenientes de m√∫ltiplas fontes, como a pr√≥pria Bloomberg, Fastmarkets e arquivos manuais, eliminando silos de informa√ß√£o e garantindo uma vis√£o √∫nica da verdade.
- **Garantir Consist√™ncia Temporal:** Manter um calend√°rio financeiro completo e cont√≠nuo, preenchendo lacunas em dias n√£o √∫teis ou feriados atrav√©s de regras de neg√≥cio bem definidas, como o *carry-forward*.
- **Aplicar Regras Audit√°veis:** Implementar toda a l√≥gica de c√°lculo e transforma√ß√£o de forma expl√≠cita e transparente, permitindo que cada n√∫mero gerado possa ser auditado e sua origem rastreada at√© a fonte bruta.
- **Entregar Indicadores Confi√°veis:** Produzir um cat√°logo de indicadores financeiros robustos e consistentes, como m√©dias m√≥veis, varia√ß√µes percentuais (MTD, YTD) e lags temporais, que sirvam como base para a tomada de decis√£o estrat√©gica.
- **Permitir Reprocessamento Controlado:** Oferecer a capacidade de reprocessar dados hist√≥ricos de forma segura e controlada, seja para corrigir regras de neg√≥cio, adicionar novos indicadores ou ajustar metadados, sem comprometer a integridade dos dados.

---

## 2. Stack Tecnol√≥gico

A arquitetura da plataforma foi constru√≠da sobre os servi√ßos da **Microsoft Azure**, utilizando uma combina√ß√£o de tecnologias serverless, de big data e de orquestra√ß√£o para garantir escalabilidade, seguran√ßa e governan√ßa. A tabela abaixo detalha a stack tecnol√≥gica utilizada em cada camada da solu√ß√£o.

| Camada | Tecnologia | Papel Estrat√©gico |
| :--- | :--- | :--- |
| **Orquestra√ß√£o** | Azure Data Factory | Respons√°vel pelo controle centralizado do fluxo de dados, gerenciando a ordem de execu√ß√£o, depend√™ncias, pol√≠ticas de *retry* e o registro de logs operacionais. Atua como o c√©rebro do processo. |
| **Ingest√£o** | Azure Functions | Utilizadas para a coleta de dados de fontes externas de forma *serverless*. Elas lidam com a autentica√ß√£o, chamadas a APIs, pagina√ß√£o de resultados e aterrissagem dos dados brutos no Data Lake. |
| **Armazenamento** | Azure Data Lake Storage Gen2 | Serve como o reposit√≥rio central para todos os dados, estruturado em camadas (RAW, Trusted, Refined). Garante a persist√™ncia da evid√™ncia hist√≥rica imut√°vel e armazena os dados processados. |
| **Processamento** | Azure Databricks (PySpark + Delta) | O cora√ß√£o da plataforma, onde todas as transforma√ß√µes, c√°lculos e regras de neg√≥cio s√£o aplicadas. O uso de PySpark permite o processamento distribu√≠do de grandes volumes de dados, e o Delta Lake garante a atomicidade e a governan√ßa das tabelas. |
| **Seguran√ßa** | Azure Key Vault + Managed Identity | Garante a gest√£o segura de segredos, chaves de API e strings de conex√£o. A autentica√ß√£o entre os servi√ßos √© realizada via *Managed Identity*, eliminando a necessidade de credenciais expostas no c√≥digo. |
| **Consumo** | Power BI / APIs / Databricks SQL | A camada final que exp√µe os dados governados aos usu√°rios. O Power BI √© utilizado para dashboards e relat√≥rios, APIs para integra√ß√£o com sistemas e o Databricks SQL para consultas anal√≠ticas ad-hoc. |

---

## 3. Arquitetura Geral (Vis√£o L√≥gica)

A arquitetura da Plataforma Bloomberg segue o modelo **Lakehouse governado**, que combina a flexibilidade e o baixo custo de um Data Lake com as garantias de ACID e a governan√ßa de um Data Warehouse. A estrutura √© dividida em planos l√≥gicos distintos, cada um com responsabilidades bem definidas, garantindo a separa√ß√£o de preocupa√ß√µes e a manutenibilidade da solu√ß√£o.

![Arquitetura L√≥gica](https://raw.githubusercontent.com/amarorn/curriculo_jose_amaro/main/plataforma_bloomberg/arquitetura_logica.png)

### Princ√≠pios Arquiteturais

A robustez da arquitetura √© sustentada por um conjunto de princ√≠pios fundamentais que guiam o desenvolvimento e a opera√ß√£o da plataforma:

- **O ADF orquestra, n√£o transforma:** O Azure Data Factory √© estritamente um orquestrador. Sua fun√ß√£o √© invocar outros servi√ßos (como Functions e Databricks) e gerenciar o fluxo, mas nunca aplicar l√≥gica de neg√≥cio ou transformar os dados diretamente.
- **Azure Functions coletam, n√£o interpretam:** As Functions s√£o respons√°veis por buscar os dados nas fontes e deposit√°-los na camada RAW da forma mais bruta poss√≠vel. Elas n√£o devem realizar nenhuma limpeza, transforma√ß√£o ou interpreta√ß√£o do conte√∫do.
- **O Data Lake √© evid√™ncia, n√£o l√≥gica:** A camada RAW do Data Lake √© um registro imut√°vel da realidade, servindo como evid√™ncia hist√≥rica. Os dados nesta camada nunca s√£o alterados, garantindo a capacidade de reprocessamento e auditoria a qualquer momento.
- **Databricks √© o √∫nico local onde regras de neg√≥cio existem:** Toda a l√≥gica de c√°lculo, transforma√ß√£o e enriquecimento de dados reside exclusivamente no ambiente Databricks. Isso centraliza as regras de neg√≥cio, facilita a manuten√ß√£o e garante que a interpreta√ß√£o dos dados seja consistente e audit√°vel.


---

## 4. Fluxo End-to-End Detalhado

O fluxo de dados da Plataforma Bloomberg √© um processo orquestrado que abrange desde a captura dos dados brutos at√© a sua disponibiliza√ß√£o para consumo. Cada etapa do fluxo possui responsabilidades claras, garantindo a integridade e a rastreabilidade do dado ao longo de sua jornada.

### 4.1 Disparo (Trigger)

A execu√ß√£o do pipeline √© iniciada por um gatilho, que pode ser configurado de diversas formas para atender √†s necessidades do neg√≥cio. √â crucial notar que, nesta fase, nenhum dado financeiro √© processado; apenas os par√¢metros de execu√ß√£o (como datas de refer√™ncia) s√£o passados para o orquestrador. Os tipos de gatilho suportados s√£o:

- **Agendamento:** Execu√ß√µes autom√°ticas em hor√°rios predefinidos (ex: diariamente √†s 08:00) ou em intervalos (intraday).
- **Execu√ß√£o Manual:** Disparos sob demanda, realizados de forma controlada por operadores para reprocessamentos ou execu√ß√µes emergenciais.
- **Evento Externo:** O fluxo pode ser iniciado em resposta a um evento em outro sistema, como a chegada de um novo arquivo em uma pasta do SharePoint.
- **Chamada via API:** Sistemas externos podem iniciar o pipeline de forma program√°tica atrav√©s de uma chamada de API segura.

### 4.2 Orquestra√ß√£o ‚Äî Azure Data Factory

O Azure Data Factory (ADF) atua como o plano de controle de todo o processo. Sua principal responsabilidade √© gerenciar o ciclo de vida da execu√ß√£o dos dados, garantindo que as etapas sejam executadas na ordem correta e com a devida resili√™ncia. As principais fun√ß√µes do ADF no fluxo s√£o:

- **Definir a Ordem de Execu√ß√£o:** Garante que os jobs de ingest√£o, processamento e carga sejam executados na sequ√™ncia correta.
- **Gerenciar Depend√™ncias:** Controla as depend√™ncias entre os diferentes pipelines e atividades.
- **Aplicar Pol√≠ticas de Resili√™ncia:** Implementa l√≥gicas de *retry* (tentativas de reexecu√ß√£o em caso de falha) e *timeout* (tempo m√°ximo de execu√ß√£o) para garantir a robustez do processo.
- **Registrar Logs de Execu√ß√£o:** Centraliza os logs operacionais, fornecendo uma vis√£o completa do que foi executado, quando e com qual resultado.

> **Regra de Ouro:** Em linha com os princ√≠pios arquiteturais, o ADF **n√£o transforma dados**. Ele apenas invoca os servi√ßos que realizam o trabalho pesado, como as Azure Functions e os jobs do Databricks.

### 4.3 Ingest√£o ‚Äî Azure Functions

A camada de aquisi√ß√£o de dados √© implementada atrav√©s de Azure Functions, que fornecem um ambiente de execu√ß√£o *serverless*, el√°stico e de baixo custo para a coleta de dados de fontes externas. As responsabilidades das Functions incluem:

- **Autentica√ß√£o Segura:** Utilizam o Azure Key Vault para obter credenciais de forma segura e se autenticar nas APIs de origem.
- **Chamada √†s APIs Externas:** Realizam as chamadas HTTP para as fontes de dados, como as APIs da Bloomberg (getData, getHistory) e da Fastmarkets.
- **Pagina√ß√£o e Controle de Volume:** Gerenciam a pagina√ß√£o dos resultados para lidar com grandes volumes de dados, garantindo que todos os registros sejam coletados.
- **Persist√™ncia em Formato Bruto:** Ap√≥s a coleta, os dados s√£o persistidos na camada RAW do Data Lake em seu formato original (JSON), geralmente compactados (.gz) para otimizar o armazenamento.

As principais fontes de dados ingeridas por este processo s√£o:

- **Bloomberg:** APIs `getData` e `getHistory` para s√©ries temporais e dados de mercado.
- **Fastmarkets:** API para cota√ß√µes de commodities espec√≠ficas.
- **SharePoint:** Arquivos manuais (Excel, CSV) contendo dados que n√£o est√£o dispon√≠veis via API.


---

## 5. Armazenamento ‚Äî Data Lake

O Azure Data Lake Storage Gen2 √© o pilar do armazenamento de dados da plataforma, organizado em um modelo de camadas (medallion architecture) que promove a governan√ßa, a qualidade e a rastreabilidade dos dados. Cada camada tem um prop√≥sito espec√≠fico, transformando os dados de seu estado bruto para um formato refinado e pronto para an√°lise.

### 5.1 Camada RAW (Landing/Bronze)

A camada RAW √© o ponto de entrada para todos os dados na plataforma. Ela funciona como uma **evid√™ncia hist√≥rica imut√°vel** do que foi recebido das fontes originais. Os dados aqui s√£o armazenados em seu formato nativo, sem qualquer tipo de transforma√ß√£o ou limpeza.

- **Caracter√≠sticas:**
    - **Dados Brutos:** C√≥pia exata do que foi entregue pela fonte.
    - **Imutabilidade:** Uma vez escritos, os dados na camada RAW nunca s√£o alterados ou exclu√≠dos. Isso √© fundamental para a auditoria e o reprocessamento.
    - **Estrutura de Pastas:** Os dados s√£o organizados por fonte, data e hora de ingest√£o, facilitando a localiza√ß√£o e o rastreamento. Exemplo: `/raw/suprimentos/bloomberg/YYYY/MM/DD/*.json.gz`.

### 5.2 Camada Trusted (Silver)

Na camada Trusted, os dados brutos passam por um primeiro n√≠vel de processamento. O objetivo desta camada √© transformar os dados de diferentes fontes em um formato padronizado e consistente, resolvendo problemas de qualidade e integrando informa√ß√µes.

- **Responsabilidades:**
    - **Normaliza√ß√£o de Schema:** Aplica um schema consistente aos dados, convertendo tipos de dados e renomeando campos para seguir um padr√£o definido.
    - **Deduplica√ß√£o:** Remove registros duplicados que possam ter sido ingeridos.
    - **Integra√ß√£o por Fonte:** Consolida os dados de uma mesma fonte em tabelas Delta unificadas.

As tabelas principais nesta camada incluem `metadata_bloomberg`, `get_history`, `dm_date`, `dm_cambio` e `manual`.

### 5.3 Camada Refined (Gold)

A camada Refined √© a camada final do Data Lake, onde os dados s√£o transformados em ativos de alto valor, prontos para o consumo. √â aqui que as regras de neg√≥cio complexas, os c√°lculos financeiros e as agrega√ß√µes s√£o aplicados para criar os Data Products finais.

- **Caracter√≠sticas:**
    - **Regras de Neg√≥cio:** Aplica√ß√£o de toda a l√≥gica de neg√≥cio, como a regra de *carry-forward* e os c√°lculos de indicadores.
    - **C√°lculos Financeiros:** Gera√ß√£o de m√©dias m√≥veis, varia√ß√µes MTD/YTD e outros indicadores financeiros.
    - **Data Marts Finais:** Cria√ß√£o dos data marts agregados e otimizados para consulta, como o `dm_bloomberg` e o `dm_dicionario`.

Os produtos desta camada s√£o a **fonte √∫nica da verdade** para todas as an√°lises e relat√≥rios da empresa.


---

## 6. Data Product ‚Äî dm_dicionario

O `dm_dicionario` √© um dos produtos de dados mais cr√≠ticos da plataforma, atuando como o **contrato sem√¢ntico** de todo o ecossistema. Sua principal fun√ß√£o √© governar os metadados dos ativos financeiros, garantindo que os tickers e identificadores sejam resolvidos de forma consistente e que as regras de prioridade entre fontes sejam aplicadas corretamente.

### Fun√ß√µes Estrat√©gicas

- **Resolver De/Para de Tickers:** Centraliza o mapeamento entre diferentes identificadores para um mesmo ativo (ex: ticker da Bloomberg, c√≥digo interno, ISIN), criando uma vis√£o unificada.
- **Definir Prioridade de Fontes:** Quando um mesmo dado est√° dispon√≠vel em mais de uma fonte, o `dm_dicionario` define qual delas √© a fonte prim√°ria, evitando ambiguidades.
- **Validar Hist√≥rico e Nome:** Cont√©m regras de valida√ß√£o, como `CHECK_NAME` e `CHECK_HIST`, que garantem a consist√™ncia dos nomes dos ativos e a integridade de suas s√©ries hist√≥ricas.

Em ess√™ncia, o `dm_dicionario` garante que todos os componentes da plataforma falem a mesma l√≠ngua, tratando os ativos financeiros de maneira uniforme e previs√≠vel.

---

## 7. Data Product ‚Äî dm_bloomberg

O `dm_bloomberg` √© o **principal Data Product** da plataforma, representando o resultado final de todo o processo de ingest√£o, processamento e enriquecimento. √â uma tabela consolidada e altamente governada que serve como a fonte √∫nica da verdade para a maioria das an√°lises financeiras da empresa.

### 7.1 Chaves de Identifica√ß√£o

A granularidade da tabela √© definida por uma chave prim√°ria composta que garante a unicidade de cada registro. A combina√ß√£o de um identificador de ativo e uma data espec√≠fica permite a constru√ß√£o de s√©ries temporais precisas.

- **`IDENTIFIER`:** O identificador principal do ativo, resolvido atrav√©s do `dm_dicionario`.
- **`ID_BB_GLOBAL`:** O identificador global da Bloomberg, para rastreabilidade com a fonte.
- **`DATE`:** A data de refer√™ncia do dado financeiro, no formato `YYYY-MM-DD`.

### 7.2 Regras Fundamentais

A confiabilidade do `dm_bloomberg` √© assegurada por um conjunto de regras de neg√≥cio fundamentais que s√£o aplicadas durante sua constru√ß√£o:

- **Calend√°rio Completo via `dm_date`:** A tabela possui um registro para cada ativo e para cada dia do calend√°rio, sem lacunas. Isso √© alcan√ßado atrav√©s de um *join* com a tabela de dimens√£o de datas (`dm_date`).
- **S√©rie Cont√≠nua por Ativo:** Para dias n√£o √∫teis ou feriados, onde n√£o h√° um novo pre√ßo, a regra de *carry-forward* √© aplicada para garantir a continuidade da s√©rie temporal.
- **Carry-forward Apenas para Pre√ßos Absolutos:** A propaga√ß√£o do √∫ltimo valor v√°lido √© aplicada **exclusivamente** a campos de pre√ßo absoluto (como `PX_LAST`). Campos de varia√ß√£o (`%Change`) nunca s√£o propagados, pois representam um evento discreto.
- **`%Change` Nunca Vira Pre√ßo:** A plataforma nunca tenta inferir um pre√ßo absoluto a partir de um campo de varia√ß√£o percentual. A varia√ß√£o √© tratada como uma informa√ß√£o distinta do pre√ßo.


---

## 8. L√≥gica de C√°lculo (Detalhada)

Todos os c√°lculos e regras de neg√≥cio s√£o executados **exclusivamente na camada Refined** do Databricks. Esta abordagem garante um isolamento crucial entre o dado bruto (evid√™ncia) e o dado interpretado (produto final), permitindo auditoria e governan√ßa completas. A seguir, detalhamos as principais l√≥gicas de c√°lculo implementadas.

### 8.1 Carry-Forward (Regra de Continuidade Temporal)

Para garantir que a s√©rie temporal de um ativo seja cont√≠nua, sem lacunas em dias n√£o √∫teis (finais de semana, feriados), a plataforma aplica a t√©cnica de *carry-forward*. Esta regra propaga o √∫ltimo pre√ßo v√°lido conhecido para os dias subsequentes que n√£o possuem um pre√ßo reportado.

![Diagrama de Sequ√™ncia do Carry-Forward](https://raw.githubusercontent.com/amarorn/curriculo_jose_amaro/main/plataforma_bloomberg/carry_forward.png)

A defini√ß√£o matem√°tica da regra √©:

```
PX_LAST_ALTERADO(d) = max(PX_LAST(t)) tal que t ‚â§ d
```

**Restri√ß√µes Importantes:**

- A regra √© aplicada **somente** a campos de pre√ßo absoluto (ex: `PX_LAST`).
- Campos que representam varia√ß√£o, como `%Change`, **nunca** s√£o propagados, pois indicam um evento que ocorreu em uma data espec√≠fica e n√£o um estado cont√≠nuo.

### 8.2 M√©dias M√≥veis

As m√©dias m√≥veis s√£o calculadas sobre o campo `PX_LAST_ALTERADO` (o pre√ßo j√° com a regra de carry-forward aplicada) para diferentes janelas de tempo. Estes indicadores s√£o fundamentais para an√°lises de tend√™ncia.

![Fluxo de C√°lculo de M√©dias M√≥veis](https://raw.githubusercontent.com/amarorn/curriculo_jose_amaro/main/plataforma_bloomberg/medias_moveis.png)

As janelas de c√°lculo padr√£o s√£o:

- `AVG_PX_LAST_30D` (M√©dia dos √∫ltimos 30 dias)
- `AVG_PX_LAST_60D` (M√©dia dos √∫ltimos 60 dias)
- `AVG_PX_LAST_90D` (M√©dia dos √∫ltimos 90 dias)
- `AVG_PX_LAST_365D` (M√©dia dos √∫ltimos 365 dias)

### 8.3 Indicadores MTD / YTD

Os indicadores *Month-To-Date* (MTD) e *Year-To-Date* (YTD) medem a varia√ß√£o de um ativo desde o in√≠cio do m√™s ou do ano corrente, respectivamente. O c√°lculo requer a identifica√ß√£o de um pre√ßo base, que √© o pre√ßo de fechamento do primeiro dia √∫til do per√≠odo.

![C√°lculo de Indicadores MTD/YTD](https://raw.githubusercontent.com/amarorn/curriculo_jose_amaro/main/plataforma_bloomberg/mtd_ytd.png)

As f√≥rmulas aplicadas s√£o:

```
CHG_NET = PX_LAST_ALTERADO - BASE
CHG_PCT = CHG_NET / BASE
```

Onde `BASE` √© o `PX_LAST_ALTERADO` do primeiro dia √∫til do m√™s (para MTD) ou do ano (para YTD). Prote√ß√µes contra divis√£o por zero s√£o aplicadas no c√°lculo de `CHG_PCT`.

### 8.4 Lags e Varia√ß√µes

A plataforma tamb√©m calcula a varia√ß√£o de pre√ßo entre a data corrente e pontos passados no tempo (lags). S√£o geradas tanto a varia√ß√£o l√≠quida (`CHG_NET_Dn`) quanto a percentual (`CHG_PCT_Dn`) para diferentes janelas `n` (1, 7, 30, 60, 90 e 365 dias). Todos os c√°lculos de varia√ß√£o percentual possuem guardas para evitar erros de divis√£o por zero.


---

## 9. Governan√ßa e Auditoria

A governan√ßa de dados √© um pilar fundamental da Plataforma Bloomberg, garantindo que os dados sejam n√£o apenas precisos, mas tamb√©m rastre√°veis, consistentes e seguros. Diversos mecanismos foram implementados para assegurar a auditoria completa do ciclo de vida do dado.

### 9.1 Rastreabilidade (Data Lineage)

Para garantir a rastreabilidade de ponta a ponta, cada registro no `dm_bloomberg` carrega metadados que permitem tra√ßar sua origem at√© o arquivo bruto na camada RAW. Os principais campos de linhagem s√£o:

- **`DL_SNAPSHOT_START_TIME`**: Timestamp que indica o momento exato em que o dado foi processado pelo Databricks.
- **`ingestion_date`**: Data em que o dado foi ingerido pela Azure Function, permitindo correlacionar com o arquivo JSON original.
- **`SOURCE_BBG`**: Campo que identifica a fonte original do dado (ex: 'Bloomberg API', 'Fastmarkets', 'Manual').

### 9.2 Persist√™ncia e Idempot√™ncia

A persist√™ncia dos dados nas camadas Trusted e Refined √© realizada utilizando o formato **Delta Lake**. O uso do Delta Lake √© crucial, pois oferece garantias de transa√ß√µes ACID (Atomicidade, Consist√™ncia, Isolamento e Durabilidade) sobre o Data Lake. As atualiza√ß√µes s√£o realizadas atrav√©s da opera√ß√£o `MERGE`, que √© **idempotente**. Isso significa que uma mesma execu√ß√£o pode ser rodada v√°rias vezes sem gerar duplicatas ou inconsist√™ncias, pois a opera√ß√£o de `MERGE` insere novos registros e atualiza os existentes com base em uma chave de neg√≥cio (a chave composta do `dm_bloomberg`).

### 9.3 Pontos de Aten√ß√£o Documentados

Parte da governan√ßa √© a transpar√™ncia sobre as regras de neg√≥cio e seus pontos de aten√ß√£o. Todas as l√≥gicas complexas e d√©bitos t√©cnicos conhecidos s√£o documentados e versionados junto ao c√≥digo. Exemplos incluem:

- A f√≥rmula exata utilizada no `CHG_PCT_MTD`, que estava em revis√£o.
- As guardas de prote√ß√£o contra divis√£o por zero aplicadas em todos os c√°lculos de `CHG_PCT_Dn`.
- A cria√ß√£o de uma coluna `month` expl√≠cita para facilitar o particionamento e a performance de consultas.


---

## 10. Opera√ß√£o, SLA e Reprocessamento

A opera√ß√£o da plataforma √© projetada para ser robusta, automatizada e com processos claros para manuten√ß√£o e recupera√ß√£o. Esta se√ß√£o detalha o fluxo operacional padr√£o, os acordos de n√≠vel de servi√ßo (SLAs) e o procedimento para reprocessamento hist√≥rico.

### 10.1 Execu√ß√£o dos Pipelines

Os pipelines s√£o executados majoritariamente de forma **di√°ria**, seguindo um cronograma que respeita a disponibilidade dos dados nas fontes e as necessidades de neg√≥cio. O fluxo operacional padr√£o segue as seguintes etapas:

1.  **Trigger no Azure Data Factory:** A execu√ß√£o √© iniciada por um gatilho, seja ele agendado ou manual.
2.  **Execu√ß√£o das Azure Functions:** O ADF invoca as Functions respons√°veis pela ingest√£o, que coletam os dados das fontes externas.
3.  **Escrita na Camada RAW:** As Functions persistem os dados brutos no Data Lake.
4.  **Disparo dos Jobs Databricks:** Ap√≥s a conclus√£o da ingest√£o, o ADF dispara os jobs no Databricks para processar os dados.
5.  **Atualiza√ß√£o das Camadas Trusted e Refined:** Os jobs do Databricks leem da camada RAW e atualizam as tabelas Delta nas camadas Trusted e Refined, aplicando toda a l√≥gica de neg√≥cio.
6.  **Disponibiliza√ß√£o para Consumo:** Uma vez que a camada Refined √© atualizada, os dados est√£o prontos para serem consumidos pelas ferramentas de BI e APIs.

### 10.2 SLA do Produto de Dados

O Data Product `dm_bloomberg` possui um Acordo de N√≠vel de Servi√ßo (SLA) claro, que define os tempos esperados para a disponibiliza√ß√£o dos dados. O monitoramento deste SLA √© realizado atrav√©s da view `controle_atualizacoes`, que √© a fonte oficial de verdade sobre o status da atualiza√ß√£o.

| Etapa | SLA Esperado (D+0) |
| :--- | :--- |
| Ingest√£o Bloomberg | At√© 09:00 |
| Processamento Trusted | At√© 10:00 |
| Processamento Refined | At√© 11:00 |
| Disponibilidade BI | At√© 12:00 |

### 10.3 Reprocessamento Hist√≥rico

A arquitetura da plataforma foi projetada para permitir o reprocessamento de dados hist√≥ricos de forma segura e rastre√°vel. Este procedimento √© necess√°rio em cen√°rios como:

-   Corre√ß√£o de uma regra de neg√≥cio que foi implementada incorretamente.
-   Inclus√£o de novos indicadores que precisam ser calculados para todo o hist√≥rico.
-   Ajuste de metadados, como um ticker de ativo que foi alterado.

O reprocessamento segue regras estritas para garantir a integridade dos dados:

-   **RAW nunca √© alterado:** O reprocessamento nunca modifica a camada de dados brutos. Ela permanece como a evid√™ncia imut√°vel.
-   **Reprocessamento parte do RAW:** Qualquer reprocessamento sempre l√™ os dados da camada RAW, garantindo que a l√≥gica corrigida seja aplicada sobre a fonte original da verdade.
-   **Execu√ß√£o Controlada:** O reprocessamento √© executado de forma controlada, geralmente para um intervalo de datas e um conjunto de identificadores espec√≠ficos, para minimizar o impacto.
-   **Impacto Rastre√°vel:** Gra√ßas ao versionamento do Delta Lake (*time travel*), √© poss√≠vel rastrear o impacto de cada reprocessamento e, se necess√°rio, reverter para uma vers√£o anterior dos dados.


---

## 11. Governan√ßa Avan√ßada e Controle de Risco

Al√©m dos mecanismos de governan√ßa padr√£o, a plataforma implementa uma s√©rie de controles avan√ßados para mitigar riscos espec√≠ficos associados a dados financeiros. O objetivo √© garantir n√£o apenas a qualidade, mas tamb√©m a resili√™ncia do Data Product contra cen√°rios de falha comuns.

### 11.1 Tipos de Risco Mitigados

A arquitetura foi desenhada para endere√ßar proativamente os seguintes riscos:

-   **Risco de Dado Ausente:** Mitigado pela combina√ß√£o da dimens√£o de calend√°rio (`dm_date`), que garante a exist√™ncia de um registro para cada dia, com a regra de *carry-forward*, que preenche os valores de pre√ßo em dias n√£o √∫teis.
-   **Risco de Dado Incorreto:** A estrita separa√ß√£o entre as camadas RAW e Refined √© o principal controle. Se um dado incorreto for ingerido, a camada RAW o preserva como evid√™ncia, e a corre√ß√£o √© aplicada na camada Refined, sem destruir o hist√≥rico original.
-   **Risco de Interpreta√ß√£o:** Centralizar todas as regras de neg√≥cio no Databricks e document√°-las de forma expl√≠cita elimina a ambiguidade e o risco de diferentes √°reas da empresa interpretarem o mesmo dado de maneiras distintas.
-   **Risco de Regress√£o:** D√©bitos t√©cnicos e pontos de aten√ß√£o s√£o documentados e versionados. Isso evita que futuras manuten√ß√µes reintroduzam problemas j√° conhecidos ou quebrem l√≥gicas de neg√≥cio estabelecidas.

### 11.2 Controles Implementados

A tabela abaixo resume os principais controles de governan√ßa e a forma como foram implementados na plataforma:

| Controle | Implementa√ß√£o |
| :--- | :--- |
| **Qualidade** | Valida√ß√µes `CHECK_NAME` e `CHECK_HIST` no `dm_dicionario` para garantir a consist√™ncia sem√¢ntica dos ativos. |
| **Rastreabilidade** | Campos de metadados como `ingestion_date` e `DL_SNAPSHOT_START_TIME` que permitem a linhagem completa do dado. |
| **Auditabilidade** | A imutabilidade da camada RAW, que serve como uma trilha de auditoria perp√©tua e confi√°vel. |
| **Consist√™ncia** | Uso da opera√ß√£o `MERGE` idempotente do Delta Lake, que previne a duplica√ß√£o de dados e garante a consist√™ncia em caso de reexecu√ß√µes. |
---

## 12. Cat√°logo de Indicadores, Gloss√°rio e Diagramas

Para facilitar o entendimento e o uso da plataforma, a documenta√ß√£o inclui cat√°logos detalhados, um gloss√°rio de termos e uma s√©rie de diagramas que ilustram a arquitetura e os fluxos de dados.

### 12.1 Cat√°logo Completo de Indicadores

A tabela a seguir apresenta um cat√°logo detalhado de todos os indicadores calculados e dispon√≠veis no `dm_bloomberg`.

| Grupo | Indicador | F√≥rmula | Base | Observa√ß√µes |
| :--- | :--- | :--- | :--- | :--- |
| Pre√ßo | `PX_LAST_ALTERADO` | `last(PX_LAST)` | Hist√≥rico | Propaga o √∫ltimo pre√ßo v√°lido. Ignora `%Change`. |
| M√©dia | `AVG_PX_LAST_30D` | `avg(PX_LAST)` | 30 dias | Calculada sobre o pre√ßo absoluto. |
| M√©dia | `AVG_PX_LAST_60D` | `avg(PX_LAST)` | 60 dias | Calculada sobre o pre√ßo absoluto. |
| M√©dia | `AVG_PX_LAST_90D` | `avg(PX_LAST)` | 90 dias | Calculada sobre o pre√ßo absoluto. |
| M√©dia | `AVG_PX_LAST_365D`| `avg(PX_LAST)` | 365 dias | Calculada sobre o pre√ßo absoluto. |
| MTD | `CHG_NET_MTD` | `PX - BASE_MTD` | M√™s | Base √© o primeiro dia √∫til do m√™s. |
| MTD | `CHG_PCT_MTD` | `CHG_NET / BASE` | M√™s | F√≥rmula em corre√ß√£o. |
| YTD | `CHG_NET_YTD` | `PX - BASE_YTD` | Ano | Base √© o primeiro dia √∫til do ano. |
| YTD | `CHG_PCT_YTD` | `CHG_NET / BASE` | Ano | Prote√ß√£o contra divis√£o por zero. |
| Lag | `PX_LAST_Dn` | `lag(PX, n)` | n dias | n ‚àà {1, 7, 30, 60, 90, 365}. |
| Var | `CHG_NET_Dn` | `PX - PX_Dn` | n dias | Diferen√ßa l√≠quida. |
| Var | `CHG_PCT_Dn` | `CHG_NET / PX_Dn`| n dias | Prote√ß√£o contra divis√£o por zero. |

### 12.2 Gloss√°rio T√©cnico-Financeiro

-   **Carry-Forward:** T√©cnica de propaga√ß√£o do √∫ltimo valor v√°lido no tempo para preencher lacunas em s√©ries temporais.
-   **%Change:** Varia√ß√£o percentual de um pre√ßo, fornecida diretamente pela fonte. √â tratada como um evento discreto e nunca como um pre√ßo absoluto.
-   **RAW:** Camada de armazenamento de dados brutos, imut√°veis, que servem como evid√™ncia hist√≥rica.
-   **Trusted:** Camada de armazenamento onde os dados s√£o padronizados, limpos e deduplicados.
-   **Refined:** Camada final de armazenamento, onde as regras de neg√≥cio s√£o aplicadas e os Data Products s√£o criados.
-   **Data Product:** Um ativo de dados que possui um dono, um SLA definido, um contrato sem√¢ntico claro e √© projetado para ser consumido por outros sistemas ou usu√°rios.

### 12.3 Diagramas C4 e de Sequ√™ncia

A documenta√ß√£o √© enriquecida com diagramas que seguem o modelo C4 (Contexto, Cont√™ineres, Componentes) e diagramas de sequ√™ncia para ilustrar os fluxos de dados. Estes diagramas s√£o mantidos em formato Mermaid no reposit√≥rio de c√≥digo, o que permite que sejam versionados e atualizados junto com a plataforma.

---

## 13. Testes, Valida√ß√µes e Observabilidade

### 13.1 Valida√ß√µes Recomendadas

- Teste de calend√°rio cont√≠nuo
- Teste de %Change n√£o propagado
- Teste de divis√£o por zero
- Teste de deduplica√ß√£o por chave

### 13.2 Observabilidade

- Logs ADF (execu√ß√£o)
- Logs Databricks (jobs)
- View `controle_atualizacoes`
- M√©tricas de SLA

---

## 14. Seguran√ßa e Compliance

- Autentica√ß√£o via Managed Identity
- Segredos centralizados no Key Vault
- Acesso segregado por camada
- Dados brutos preservados

---

## 15. Roadmap T√©cnico

- Corre√ß√£o `CHG_PCT_MTD`
- Guardas universais em `CHG_PCT_D*`
- Testes automatizados
- M√©tricas de SLA em dashboard
- Parametriza√ß√£o total de pipelines

---

## 16. Conclus√£o Final

Este documento representa a **documenta√ß√£o t√©cnica completa e oficial** da Plataforma Bloomberg. Ele descreve, com a m√°xima profundidade, a arquitetura, os fluxos, os c√°lculos, as regras de neg√≥cio, a opera√ß√£o e a governan√ßa da solu√ß√£o. Deve ser tratado como a **fonte √∫nica da verdade** e a base para toda a evolu√ß√£o futura deste Data Product.
